---
title: 深度学习行为识别主要方法总结
mathjax: true
type: categories
categories: 论文总结

---



#####基本方法

目前对于基于深度学习视频行为识别的算法主要可以分为**3**大类：(*未考虑RNN方法, RNN训练难度较CNN更大，同时最后在识别精度上与要逊色于CNN方法。*)

> 1、以two-stream为代表的方法
>
> 2、以C3D、I3D为代表的方法
>
> 3、以pseudo-3D为代表的方法

##### two-stream方法：

two-stream将RGB图像与光流图像作为输入，基础网络是inception-v1网络。目前  [**TSN**](https://arxiv.org/abs/1608.00859)(temporary segment network)在UCF101上能达到94%的正确率，效果十分出众。TSN网络的结构如下图所示：

![TSN](https://github.com/izhaolei/images/blob/master/tsn.JPG?raw=true)

TSN最后的结果是两个网络的ensemble，效果出众。

##### C3D与I3D方法：

[C3D](http://vlg.cs.dartmouth.edu/c3d/c3d_video.pdf)最早直接将RGB图像序列作为输入，构建3D卷积操作，区别于传统的2D kernel，3D卷积只是增加了时间 (temporary) 这一维度。C3D在识别上速度更快，同时训练上由于是end-end的方式，也更简单，但是C3D计算量巨大，很难讲目前在图像上十分成功的深层网络 (ResNet152、DPN107) 改进为C3D结构。

[I3D](https://arxiv.org/abs/1705.07750) (Inception 3D) 是将2D的Inception网络拓展为3D的例子，这也为构建3D网络提供了一种思路，而不用重新训练一个3D网络。在文中作者将Inception扩展为3D结构，利用在ImageNet上训练好的权重去初始化网络。

##### pseudo-3D

[pseudo-3D](http://openaccess.thecvf.com/content_iccv_2017/html/Qiu_Learning_Spatio-Temporal_Representation_ICCV_2017_paper.html)这是今年ICCV上的一篇文章，这篇文章可以看做是temporary separate convolution，作者将传统的3D卷积进行拆分，比如$K\times K\times K$的3D卷积核可以拆分为$1\times K\times K$和$K\times 1\times 1$的两个卷积操作的几年，这样大大的降低了运算量，同时可以达到相当好的性能。同时这样的结构有利于将图像分类上的优秀网络进行迁移。